# Exploration-and-Experience-Replay-RL-Strategies-in-Lunar-Lander-v3

This repository contains the implementation and analysis of Proximal Policy Optimization (PPO) and Deep Q-Network (DQN) algorithms in the Farama Foundation's Atari LunarLander-v3 reinforcement learning environment. The focus is on evaluating the effectiveness of different exploration and experience replay strategies, specifically Boltzmann Exploration and Prioritized Experience Replay (PER). Additionally, a Soft Actor-Critic (SAC) model is provided for extended evaluation.

- Key components of this repository include:
    - Baseline implementations of PPO, DQN, and experimental implementation of SAC 
    - Integration and comparison of Boltzmann Exploration and Prioritized Experience Replay in DQN framework.
    - Detailed visualizations demonstrating training outcomes and performance comparisons.
    - Thorough explanations of methodological choices and their impacts on model training.

This project serves as a practical exploration of advanced reinforcement learning techniques, suitable for understanding their impact on training stability and performance efficiency.
